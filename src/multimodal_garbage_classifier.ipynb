{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5ryJG9EgVil"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dM2umeGQgU52"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONR_dn1rgenx"
      },
      "source": [
        "# Initialize Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjDnaBubghEq",
        "outputId": "db2aab2e-2fff-4a30-a306-56100511a280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8GtMjeBgmRv"
      },
      "source": [
        "# Static Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pLNzjcNygoNP"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.0001\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "# dataset directories\n",
        "TRAINSET_DIR = '/work/TALC/enel645_2024f/garbage_data/CVPR_2024_dataset_Train'\n",
        "VALSET_DIR = '/work/TALC/enel645_2024f/garbage_data/CVPR_2024_dataset_Val'\n",
        "TESTSET_DIR = '/work/TALC/enel645_2024f/garbage_data/CVPR_2024_dataset_Test'\n",
        "\n",
        "# global class to index mapping variables\n",
        "class_names = ['Green', 'Blue', 'Black', 'TTR']\n",
        "class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
        "idx_to_class = {idx: class_name for class_name, idx in class_to_idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx9MZqy2gq2y"
      },
      "source": [
        "# Class Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "os8Vw8WhgtBc"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**GarbageDataset**\n",
        "\n",
        "This class loads data from a DataFrame containing image paths, text descriptions, and labels. It applies image\n",
        "transformations, tokenizes text descriptions, and maps labels to numeric values for training a deep learning model.\n",
        "\n",
        "Attributes:\n",
        "    dataframe (pd.DataFrame): The input DataFrame containing 'image_path', 'text_description', and 'label' columns.\n",
        "    image_transform (callable, optional): Image transformation function to preprocess images.\n",
        "    max_len (int): Maximum length for text tokenization (default: 32).\n",
        "    tokenizer (transformers.PreTrainedTokenizer, optional): Tokenizer for text processing.\n",
        "    class_to_idx (dict): Mapping of class labels to numeric indices for model training.\n",
        "\n",
        "Methods:\n",
        "    __len__(): Returns the number of samples in the dataset.\n",
        "    __getitem__(idx): Retrieves the image, tokenized text, and label for a given index.\n",
        "\n",
        "        Inputs:\n",
        "            idx (int): Index of the data sample to retrieve.\n",
        "        Outputs:\n",
        "            dict: A dictionary containing:\n",
        "                - 'image' (torch.Tensor): The preprocessed image tensor.\n",
        "                - 'input_ids' (torch.Tensor): The tokenized text input IDs.\n",
        "                - 'attention_mask' (torch.Tensor): Attention mask for tokenized text.\n",
        "                - 'label' (torch.Tensor): Numeric label for classification.\n",
        "                - 'text_description' (str): Original text description for reference.\n",
        "\"\"\"\n",
        "class GarbageDataset(Dataset):\n",
        "    # Initialize the dataset with a dataframe\n",
        "    def __init__(self, dataframe, image_transform=None, max_len=32, tokenizer=None, class_to_idx=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.image_transform = image_transform\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.class_to_idx = class_to_idx\n",
        "\n",
        "        # Cache for storing tokenized descriptions to avoid re-tokenizing duplicate descriptions\n",
        "        self._token_cache = {}\n",
        "\n",
        "    # Return the number of samples in the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get image path, text description, and label from the dataframe\n",
        "        img_path = self.dataframe.iloc[idx]['image_path']\n",
        "        text_desc = self.dataframe.iloc[idx]['text_description']\n",
        "        label = self.dataframe.iloc[idx]['label']\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Transform the image\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "\n",
        "        # Tokenize the text description using caching\n",
        "        if text_desc in self._token_cache:\n",
        "            text_inputs = self._token_cache[text_desc]\n",
        "        else:\n",
        "            text_inputs = self.tokenizer(\n",
        "                text_desc,\n",
        "                add_special_tokens=True,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                max_length=self.max_len,\n",
        "                return_token_type_ids=False,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            self._token_cache[text_desc] = text_inputs\n",
        "\n",
        "        # Convert string label to numeric label using the class mapping\n",
        "        numeric_label = self.class_to_idx[label]\n",
        "\n",
        "        # Return the image, text input, and numeric label\n",
        "        return {\n",
        "            'image': image,\n",
        "            'input_ids': text_inputs['input_ids'].squeeze(0),\n",
        "            'attention_mask': text_inputs['attention_mask'].squeeze(0),\n",
        "            'label': torch.tensor(numeric_label, dtype=torch.long),\n",
        "            'text_description': text_desc  # For logging misclassified examples\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "i7-90XIZhGb0"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**ImageModel**\n",
        "\n",
        "This model loads a ResNet-50 model, removes its final classification layer, and replaces it with a custom\n",
        "feature extraction layer to output a 512-dimensional feature vector for each image. A dropout layer is applied\n",
        "to prevent overfitting.\n",
        "\n",
        "Attributes:\n",
        "    dropout_rate (float): Dropout probability applied in the feature extraction layer (default: 0.5).\n",
        "    model (torchvision.models.ResNet): Pre-trained ResNet-50 model with the classification layer removed.\n",
        "    feature_extractor (nn.Sequential): Sequential layers containing a linear transformation, ReLU activation,\n",
        "        and dropout, which outputs a 512-dimensional feature vector.\n",
        "\n",
        "Methods:\n",
        "    forward(x): Passes an input image through the ResNet-50 backbone and feature extractor.\n",
        "\n",
        "        Inputs:\n",
        "            x (torch.Tensor): Input image tensor with shape (batch_size, 3, H, W).\n",
        "\n",
        "        Outputs:\n",
        "            torch.Tensor: A 512-dimensional feature vector for each input image, with shape (batch_size, 512).\n",
        "\"\"\"\n",
        "class ImageModel(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.2):\n",
        "        # Initialize the model\n",
        "        super(ImageModel, self).__init__()\n",
        "\n",
        "        # Load a pre-trained ResNet50 model with default weights\n",
        "        self.model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "\n",
        "        # Remove the last classification layer\n",
        "        self.model.fc = nn.Identity()\n",
        "\n",
        "        # Feature extractor to output a feature vector\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through the ResNet50 model up to the last layer (output shape: batch_size x 2048)\n",
        "        x = self.model(x)\n",
        "\n",
        "        # Process the features and produce a 512-dimensional feature vector\n",
        "        x = self.feature_extractor(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9PwcvGtChHUT"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**TextModel**\n",
        "\n",
        "This model uses a pre-trained BERT architecture to generate contextual embeddings from text input.\n",
        "It extracts the representation of the [CLS] token and processes it through a dropout layer and a\n",
        "linear transformation to produce a 512-dimensional feature vector for classification tasks.\n",
        "\n",
        "Attributes:\n",
        "    dropout_rate (float): Dropout probability applied after the [CLS] token extraction (default: 0.5).\n",
        "    pretrained_model_name (str): The name of the pre-trained BERT model to be used (default: 'bert-base-uncased').\n",
        "    bert (transformers.BertModel): The BERT model for extracting embeddings.\n",
        "    dropout (nn.Dropout): Dropout layer for regularization.\n",
        "    feature_extractor (nn.Linear): Linear layer that reduces the BERT output to a 512-dimensional feature vector.\n",
        "\n",
        "Methods:\n",
        "    forward(input_ids, attention_mask): Passes tokenized text input through the BERT model and feature extractor.\n",
        "\n",
        "        Inputs:\n",
        "            input_ids (torch.Tensor): Input tensor containing token IDs with shape (batch_size, max_length).\n",
        "            attention_mask (torch.Tensor): Attention mask tensor indicating valid tokens with shape (batch_size, max_length).\n",
        "\n",
        "        Outputs:\n",
        "            torch.Tensor: A 512-dimensional feature vector for each input sequence, with shape (batch_size, 512).\n",
        "\"\"\"\n",
        "class TextModel(nn.Module):\n",
        "    # Initialize the TextModel and load a pretrained BERT model\n",
        "    def __init__(self, dropout_rate=0.5, pretrained_model_name='bert-base-uncased'):\n",
        "        super(TextModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(pretrained_model_name)\n",
        "\n",
        "        # Define a dropout layer for regularization\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Define a linear layer to map the BERT output size to a smaller 512-dimensional feature vector\n",
        "        self.feature_extractor = nn.Linear(self.bert.config.hidden_size, 512)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Pass the input IDs and attention mask through the BERT model to get the outputs\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Extract the CLS token embedding from the last hidden state (the first token of the output)\n",
        "        cls_token_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Apply dropout to the CLS token embedding for regularization\n",
        "        pooled_output = self.dropout(cls_token_embedding)\n",
        "\n",
        "        # Pass the pooled output through the feature extractor to obtain the final text features\n",
        "        text_features = self.feature_extractor(pooled_output)\n",
        "\n",
        "        return text_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kxLDXqubhJad"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**GarbageClassifier**\n",
        "\n",
        "This model integrates features extracted from images using a ResNet-50 backbone and text features using a\n",
        "BERT model. The output from both models is concatenated and processed through several fully connected layers\n",
        "to produce class predictions for garbage classification.\n",
        "\n",
        "Attributes:\n",
        "    num_classes (int): The number of output classes for classification (default: 4).\n",
        "    dropout_rate (float): Dropout probability applied in the fusion layers (default: 0.5).\n",
        "    image_model (ImageModel): Instance of the image feature extraction model.\n",
        "    text_model (TextModel): Instance of the text feature extraction model.\n",
        "    fusion (nn.Sequential): Sequential layers for combining features and outputting class predictions.\n",
        "\n",
        "Methods:\n",
        "    forward(image, input_ids, attention_mask): Combines image and text features to make class predictions.\n",
        "\n",
        "        Inputs:\n",
        "            image (torch.Tensor): Input image tensor with shape (batch_size, 3, H, W).\n",
        "            input_ids (torch.Tensor): Input tensor containing token IDs with shape (batch_size, max_length).\n",
        "            attention_mask (torch.Tensor): Attention mask tensor indicating valid tokens with shape (batch_size, max_length).\n",
        "\n",
        "        Outputs:\n",
        "            torch.Tensor: Class predictions with shape (batch_size, num_classes).\n",
        "\"\"\"\n",
        "class GarbageClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=4, dropout_rate=0.5):\n",
        "        # Initialize the classifier\n",
        "        super(GarbageClassifier, self).__init__()\n",
        "\n",
        "        # Get the image model\n",
        "        self.image_model = ImageModel(dropout_rate=dropout_rate)\n",
        "\n",
        "        # Get the text model\n",
        "        self.text_model = TextModel(dropout_rate=dropout_rate)\n",
        "\n",
        "        # Delcare the fusion and classification layers\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(512 + 512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, input_ids, attention_mask):\n",
        "        # Get image features - Shape: (batch_size, 512)\n",
        "        image_features = self.image_model(image)\n",
        "\n",
        "        # Get text features (logits) - Shape: (batch_size, num_classes)\n",
        "        text_features = self.text_model(input_ids, attention_mask)\n",
        "\n",
        "        # Combined features - Shape: (batch_size, 512 + num_classes)\n",
        "        combined_features = torch.cat((image_features, text_features), dim=1)\n",
        "\n",
        "        # Combined prediction - Shape: (batch_size, num_classes)\n",
        "        combined_output = self.fusion(combined_features)\n",
        "\n",
        "        return combined_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwQB296-g6ao"
      },
      "source": [
        "# Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WFfroVZYg8wT"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**extract_data_from_folders**\n",
        "\n",
        "This function traverses through a specified base directory containing subfolders. Each subfolder represents a\n",
        "distinct class label, and it extracts image file paths, generates text descriptions from the filenames, and\n",
        "associates them with their respective labels. The resulting data is compiled into a pandas DataFrame for\n",
        "convenient processing and manipulation.\n",
        "\n",
        "Args:\n",
        "    base_dir (str): The path to the base directory containing subfolders with images.\n",
        "\n",
        "Returns:\n",
        "    pd.DataFrame: A DataFrame containing the extracted information with columns:\n",
        "        - 'image_path': Path to the image file.\n",
        "        - 'text_description': A text description generated from the filename, cleaned of digits and underscores.\n",
        "        - 'label': The name of the subfolder, representing the class label for the images.\n",
        "\"\"\"\n",
        "def extract_data_from_folders(base_dir):\n",
        "    data = []\n",
        "\n",
        "    # Traverse through each subfolder\n",
        "    for label_folder in os.listdir(base_dir):\n",
        "        folder_path = os.path.join(base_dir, label_folder)\n",
        "\n",
        "        # Check if it's a directory\n",
        "        if os.path.isdir(folder_path):\n",
        "            # Loop through each image file in the subfolder\n",
        "            for filename in os.listdir(folder_path):\n",
        "                # Filter through image files\n",
        "                if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
        "                    image_path = os.path.join(folder_path, filename)\n",
        "\n",
        "                    # Extract text from filename (remove file extension)\n",
        "                    text_description = os.path.splitext(filename)[0]\n",
        "\n",
        "                    # Append image path, text, and label to the data list\n",
        "                    text = text_description.replace('_', ' ')\n",
        "                    text_without_digits = re.sub(r'\\d+', '', text).strip().lower()\n",
        "                    data.append({\n",
        "                        'image_path': image_path,\n",
        "                        'text_description': text_without_digits,\n",
        "                        # The subfolder name represents the label\n",
        "                        'label': label_folder\n",
        "                    })\n",
        "\n",
        "    # Convert to DataFrame for easy manipulation\n",
        "    return pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "B8-RLMvDhndU"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**compute_class_weights**\n",
        "\n",
        "This function calculates weights for each class based on their frequency in the training dataset.\n",
        "It uses the `compute_class_weight` function from sklearn to generate weights that can be used\n",
        "to mitigate the impact of imbalanced class distribution during training. The resulting weights\n",
        "are returned as a tensor for use in model training.\n",
        "\n",
        "Args:\n",
        "    trainset_df (pd.DataFrame): DataFrame containing the training dataset with a column 'label'\n",
        "                                    representing the class labels.\n",
        "\n",
        "Returns:\n",
        "    torch.Tensor: A tensor containing the computed class weights, where each weight corresponds\n",
        "                    to a class in the dataset.\n",
        "\"\"\"\n",
        "def compute_class_weights(trainset_df):\n",
        "    # Extract unique class labels from the 'label' column of the training set DataFrame.\n",
        "    class_labels = np.unique(trainset_df['label'])\n",
        "\n",
        "    # Calculate the class weights using the compute_class_weight function from sklearn.\n",
        "    class_weights = compute_class_weight(\n",
        "        'balanced',\n",
        "        classes=class_labels,\n",
        "        y=trainset_df['label']\n",
        "    )\n",
        "\n",
        "    # Create a mapping from class labels to their corresponding weights.\n",
        "    class_weights_dict = {label: weight for label, weight in zip(class_labels, class_weights)}\n",
        "\n",
        "    # Map the class weights to the class indices defined in the variable class_names.\n",
        "    class_weights_list = [class_weights_dict[class_name] for class_name in class_names]\n",
        "\n",
        "    # Convert the list of class weights into a PyTorch tensor and move it to the specified device (CPU or GPU).\n",
        "    class_weights_tensor = torch.tensor(class_weights_list, dtype=torch.float).to(device)\n",
        "\n",
        "    return class_weights_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LpRcv27ChoZI"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**data_preprocessing**\n",
        "\n",
        "This function handles the following tasks:\n",
        "1. Extracts image paths, text descriptions, and labels from specified directories for training, validation,\n",
        "    and test datasets.\n",
        "2. Computes class weights to address class imbalance.\n",
        "3. Initializes the BERT tokenizer for text processing.\n",
        "4. Defines image transformations for both training and testing datasets.\n",
        "5. Creates instances of the `GarbageDataset` class for each dataset.\n",
        "6. Initializes DataLoaders for efficient batching and shuffling of the datasets.\n",
        "\n",
        "Returns:\n",
        "    tuple: A tuple containing:\n",
        "        - trainloader (DataLoader): DataLoader for the training dataset.\n",
        "        - valloader (DataLoader): DataLoader for the validation dataset.\n",
        "        - testloader (DataLoader): DataLoader for the test dataset.\n",
        "        - class_weights_tensor (torch.Tensor): Tensor containing the computed class weights.\n",
        "\"\"\"\n",
        "def data_preprocessing():\n",
        "    # Extract the data from the specified directories for training, validation, and testing\n",
        "    trainset_df = extract_data_from_folders(TRAINSET_DIR)\n",
        "    valset_df = extract_data_from_folders(VALSET_DIR)\n",
        "    testset_df = extract_data_from_folders(TESTSET_DIR)\n",
        "\n",
        "    # Compute class weights to address any class imbalance in the training set\n",
        "    class_weights_tensor = compute_class_weights(trainset_df)\n",
        "\n",
        "    # Initialize the BERT tokenizer for processing text data\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Define image transformations for the training set, including resizing, data augmentation, and normalization\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize images to 224x224 pixels\n",
        "        transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally for augmentation\n",
        "        transforms.RandomRotation(10),  # Randomly rotate images by up to 10 degrees for augmentation\n",
        "        transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n",
        "        transforms.Normalize(  # Normalize the images with specified mean and standard deviation values\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    # Define image transformations for the test set, which do not include augmentation\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize images to 224x224 pixels\n",
        "        transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n",
        "        transforms.Normalize(  # Normalize the images with specified mean and standard deviation values\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    # Create datasets for training, validation, and testing using the GarbageDataset class\n",
        "    trainset = GarbageDataset(\n",
        "        trainset_df,\n",
        "        image_transform=transform_train,\n",
        "        class_to_idx=class_to_idx,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=32\n",
        "    )\n",
        "    valset = GarbageDataset(\n",
        "        valset_df,\n",
        "        image_transform=transform_train,\n",
        "        class_to_idx=class_to_idx,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=32\n",
        "    )\n",
        "    testset = GarbageDataset(\n",
        "        testset_df,\n",
        "        image_transform=transform_test,\n",
        "        class_to_idx=class_to_idx,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=32\n",
        "    )\n",
        "\n",
        "    # Create DataLoader objects for training, validation, and testing, specifying batch size and number of workers\n",
        "    trainloader = DataLoader(\n",
        "        trainset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "    valloader = DataLoader(\n",
        "        valset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "    testloader = DataLoader(\n",
        "        testset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    # Return the DataLoader objects and the class weights tensor for use in training and evaluation\n",
        "    return trainloader, valloader, testloader, class_weights_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "V_Qljso0h-Nt"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**compute_metrics**\n",
        "\n",
        "This function calculates precision, recall, and F1-score using the true labels and predicted labels.\n",
        "The metrics are computed using the `precision_score`, `recall_score`, and `f1_score` functions from\n",
        "sklearn, with a focus on the weighted average to account for class imbalance.\n",
        "\n",
        "Args:\n",
        "    all_labels (list or np.ndarray): True labels for the dataset.\n",
        "    all_preds_combined (list or np.ndarray): Predicted labels from the model.\n",
        "\n",
        "Returns:\n",
        "    tuple: A tuple containing:\n",
        "        - precision (float): The precision score of the predictions.\n",
        "        - recall (float): The recall score of the predictions.\n",
        "        - f1 (float): The F1 score of the predictions.\n",
        "\"\"\"\n",
        "def compute_metrics(all_labels, all_preds_combined):\n",
        "    # Calculate precision, using a 'weighted' average to account for class imbalance\n",
        "    precision = precision_score(\n",
        "        all_labels, all_preds_combined, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Calculate recall, which measures the ability of the model to find all the relevant instances\n",
        "    recall = recall_score(\n",
        "        all_labels, all_preds_combined, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Calculate the F1 score, which is the harmonic mean of precision and recall\n",
        "    f1 = f1_score(\n",
        "        all_labels, all_preds_combined, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Return the computed precision, recall, and F1 score\n",
        "    return precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QugqY3IVhkgi"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**plot_training_results**\n",
        "\n",
        "This function generates a 2x2 grid of plots to visualize the training and validation metrics\n",
        "across epochs. It handles both tensor and NumPy array inputs, ensuring compatibility with\n",
        "GPU tensors by moving them to the CPU.\n",
        "\n",
        "Args:\n",
        "    train_losses (list): A list of training loss values for each epoch.\n",
        "    val_losses (list): A list of validation loss values for each epoch.\n",
        "    train_accuracies (list): A list of training accuracy values for each epoch.\n",
        "    val_accuracies (list): A list of validation accuracy values for each epoch.\n",
        "    precisions (list): A list of precision values for each epoch.\n",
        "    recalls (list): A list of recall values for each epoch.\n",
        "    f1_scores (list): A list of F1 scores for each epoch.\n",
        "    filename (str): The filename for saving the plotted figure.\n",
        "\n",
        "Returns:\n",
        "    None\n",
        "\"\"\"\n",
        "def plot_training_results(train_losses, val_losses, train_accuracies, val_accuracies, precisions, recalls, f1_scores, filename):\n",
        "    # Convert list of tensors to NumPy arrays if they are on GPU to enable plotting\n",
        "    train_losses = [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in train_losses]\n",
        "    val_losses = [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in val_losses]\n",
        "    train_accuracies = [acc.detach().cpu().numpy() if isinstance(acc, torch.Tensor) else acc for acc in train_accuracies]\n",
        "    val_accuracies = [acc.detach().cpu().numpy() if isinstance(acc, torch.Tensor) else acc for acc in val_accuracies]\n",
        "    precisions = [precision.detach().cpu().numpy() if isinstance(precision, torch.Tensor) else precision for precision in precisions]\n",
        "    recalls = [recall.detach().cpu().numpy() if isinstance(recall, torch.Tensor) else recall for recall in recalls]\n",
        "    f1_scores = [f1.detach().cpu().numpy() if isinstance(f1, torch.Tensor) else f1 for f1 in f1_scores]\n",
        "\n",
        "    # Create a list of epochs corresponding to the number of training iterations\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "    epochs = list(epochs)\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label='Training Loss')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
        "    plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Precision\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(epochs, precisions, label='Precision')\n",
        "    plt.title('Validation Precision')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Recall and F1 Score\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(epochs, recalls, label='Recall')  #\n",
        "    plt.plot(epochs, f1_scores, label='F1 Score')\n",
        "    plt.title('Validation Recall and F1 Score')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Score')\n",
        "    plt.legend()\n",
        "\n",
        "    # adjust layout, save file, and close to save memory\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lzohD5BuhtMX"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**plot_confusion_matrix**\n",
        "\n",
        "This function generates a heatmap visualization of the confusion matrix using Seaborn.\n",
        "The matrix shows the number of correct and incorrect predictions for each class, allowing\n",
        "for an intuitive understanding of the model's performance.\n",
        "\n",
        "Args:\n",
        "    conf_mat (ndarray): A confusion matrix, typically computed from the test set predictions.\n",
        "\n",
        "Returns:\n",
        "    None\n",
        "\"\"\"\n",
        "def plot_confusion_matrix(conf_mat, filename):\n",
        "    # Create a figure and axis for the confusion matrix plot\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "    # Use seaborn's heatmap to visualize the confusion matrix\n",
        "    sns.heatmap(\n",
        "        conf_mat,  # The confusion matrix to plot\n",
        "        annot=True,  # Annotate each cell with the numeric value\n",
        "        fmt='d',  # Format of the annotation as integers\n",
        "        cmap='Blues',  # Color map for the heatmap\n",
        "        xticklabels=class_names,  # X-axis labels as class names for predicted labels\n",
        "        yticklabels=class_names  # Y-axis labels as class names for actual labels\n",
        "    )\n",
        "\n",
        "    # Add title and axis lables\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.title('Test Confusion Matrix')\n",
        "\n",
        "    # Save and close the figure\n",
        "    plt.savefig(filename)\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sOlYQwU7hOvp"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**train_one_epoch**\n",
        "\n",
        "This function performs a single training pass over the provided dataset. It iterates through\n",
        "the training data, performs forward and backward passes, computes the loss, and updates the model weights.\n",
        "The function also tracks the running loss and accuracy for the epoch.\n",
        "\n",
        "Args:\n",
        "    model (nn.Module): The model to be trained.\n",
        "    trainloader (DataLoader): The DataLoader for the training dataset.\n",
        "    criterion (nn.Module): The loss function used for training.\n",
        "    optimizer (torch.optim.Optimizer): The optimizer used for updating model weights.\n",
        "\n",
        "Returns:\n",
        "    tuple: A tuple containing:\n",
        "        - epoch_loss_combined (float): The average loss for the epoch.\n",
        "        - epoch_acc_combined (float): The average accuracy for the epoch.\n",
        "\"\"\"\n",
        "def train_one_epoch(model, trainloader, criterion, optimizer):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Initialize variables to track the cumulative loss and correct predictions\n",
        "    running_loss_combined = 0.0\n",
        "    running_corrects_combined = 0\n",
        "\n",
        "    # Iterate over the training data provided by the DataLoader\n",
        "    for i, batch in enumerate(trainloader):\n",
        "        # Move images and labels to specified device\n",
        "        images = batch['image'].to(device)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        # Clear the gradients of the optimizer before each forward pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass through the model\n",
        "        combined_outputs = model(\n",
        "            images, input_ids, attention_mask\n",
        "        )\n",
        "\n",
        "        # Compute the loss using the specified criterion\n",
        "        loss_combined = criterion(combined_outputs, labels)\n",
        "\n",
        "        # Backward pass to compute gradients and optimize the model\n",
        "        loss_combined.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the cumulative loss with the loss from this batch\n",
        "        running_loss_combined += loss_combined.item() * images.size(0)\n",
        "\n",
        "        # Get predictions by selecting the class with the highest score\n",
        "        _, preds_combined = torch.max(combined_outputs, 1)\n",
        "\n",
        "        # Update the count of correct predictions\n",
        "        running_corrects_combined += torch.sum(preds_combined == labels.data)\n",
        "\n",
        "    # Compute epoch loss and accuracy for the epoch\n",
        "    epoch_loss_combined = running_loss_combined / len(trainloader.dataset)\n",
        "    epoch_acc_combined = running_corrects_combined.double() / len(trainloader.dataset)\n",
        "\n",
        "    return epoch_loss_combined, epoch_acc_combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jt_Gd8jJhVW5"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**validate**\n",
        "\n",
        "This function evaluates the model's performance on the validation set by calculating the validation loss,\n",
        "accuracy, and additional metrics such as precision, recall, and F1 score. It uses the model in evaluation mode\n",
        "and disables gradient computation to save memory and improve performance during inference.\n",
        "\n",
        "Args:\n",
        "    model (nn.Module): The neural network model to validate.\n",
        "    valloader (DataLoader): The DataLoader for the validation dataset.\n",
        "    criterion (nn.Module): The loss function used to compute loss.\n",
        "\n",
        "Returns:\n",
        "    tuple: A tuple containing:\n",
        "        - float: The computed validation loss.\n",
        "        - float: The computed validation accuracy.\n",
        "        - float: The computed precision.\n",
        "        - float: The computed recall.\n",
        "        - float: The computed F1 score.\n",
        "\"\"\"\n",
        "def validate(model, valloader, criterion):\n",
        "    # Set the model to evaluation mode, disabling dropout and batch normalization\n",
        "    model.eval()\n",
        "\n",
        "    val_running_loss_combined = 0.0  # Initialize the total loss for the validation set\n",
        "    val_running_corrects_combined = 0  # Initialize the count of correct predictions\n",
        "\n",
        "    all_labels = []  # List to store all true labels for metrics computation\n",
        "    all_preds_combined = []  # List to store all predictions for metrics computation\n",
        "\n",
        "    # Disable gradient calculation for validation (saves memory and computation)\n",
        "    with torch.no_grad():\n",
        "        for batch in valloader:\n",
        "            # Move data to the appropriate device\n",
        "            images = batch['image'].to(device)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # Forward pass: compute model outputs for the current batch\n",
        "            combined_outputs = model(\n",
        "                images, input_ids, attention_mask\n",
        "            )\n",
        "\n",
        "            # Compute the loss between predicted outputs and true labels\n",
        "            loss_combined = criterion(combined_outputs, labels)\n",
        "\n",
        "            # Update the running loss for the validation set\n",
        "            val_running_loss_combined += loss_combined.item() * images.size(0)\n",
        "\n",
        "            # Get predictions by finding the class with the maximum score\n",
        "            _, preds_combined = torch.max(combined_outputs, 1)\n",
        "\n",
        "            # Update the count of correct predictions\n",
        "            val_running_corrects_combined += torch.sum(\n",
        "                preds_combined == labels.data\n",
        "            )\n",
        "\n",
        "            # Collect all labels and predictions for metric computations\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds_combined.extend(preds_combined.cpu().numpy())\n",
        "\n",
        "    # Compute the average validation loss and accuracy\n",
        "    val_loss_combined = val_running_loss_combined / len(valloader.dataset)\n",
        "    val_acc_combined = val_running_corrects_combined.double() / len(valloader.dataset)\n",
        "\n",
        "    # Compute additional metrics such as precision, recall, and F1 score\n",
        "    precision, recall, f1 = compute_metrics(all_labels, all_preds_combined)\n",
        "\n",
        "    # Return the computed validation loss, accuracy, and metrics\n",
        "    return val_loss_combined, val_acc_combined, precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpYyfU3l1S67"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**train_validate_model**\n",
        "\n",
        "This function handles the entire training process for a given model, including training and\n",
        "validation phases. It tracks the loss and accuracy metrics for both phases, implements early stopping\n",
        "based on validation loss, and saves the best-performing model. A learning rate scheduler is also used\n",
        "to adjust the learning rate during training.\n",
        "\n",
        "Args:\n",
        "    model (nn.Module): The neural network model to be trained and validated.\n",
        "    trainloader (DataLoader): The DataLoader for the training dataset.\n",
        "    valloader (DataLoader): The DataLoader for the validation dataset.\n",
        "    criterion (nn.Module): The loss function used to compute loss.\n",
        "    trainable_params (iterable): An iterable of parameters to optimize.\n",
        "    best_val_loss (float): The best validation loss encountered during training.\n",
        "    num_epochs (int): The total number of epochs to train the model.\n",
        "\n",
        "Returns:\n",
        "    float: The best validation loss achieved during training.\n",
        "\"\"\"\n",
        "def train_validate_model(model, trainloader, valloader, criterion, trainable_params, best_val_loss, num_epochs, filename):\n",
        "    # Initialize the Adam optimizer with a learning rate and weight decay for regularization\n",
        "    optimizer = optim.Adam(trainable_params, lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "\n",
        "    # Parameters for early stopping to prevent overfitting.=\n",
        "    early_stopping_patience = 4  # Number of epochs to wait before stopping if no improvement\n",
        "    epochs_no_improve = 0  # Counter for epochs without improvement in validation loss\n",
        "\n",
        "    # Lists to store training and validation metrics for plotting later\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "\n",
        "    # Learning rate scheduler to reduce the learning rate after a certain number of epochs\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "\n",
        "    # Loop through the specified number of epochs for training and validation\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase: call the training function for one epoch\n",
        "        epoch_loss_combined, epoch_acc_combined = train_one_epoch(\n",
        "            model, trainloader, criterion, optimizer\n",
        "        )\n",
        "\n",
        "        # Append training metrics to the respective lists\n",
        "        train_losses.append(epoch_loss_combined)\n",
        "        train_accuracies.append(epoch_acc_combined)\n",
        "\n",
        "        print(f'Training Combined Loss: {epoch_loss_combined:.4f} '\n",
        "                f'Acc: {epoch_acc_combined:.4f}')\n",
        "\n",
        "        # Validation phase: evaluate the model on the validation set\n",
        "        val_loss_combined, val_acc_combined, precision, recall, f1 = validate(\n",
        "            model, valloader, criterion\n",
        "        )\n",
        "\n",
        "        # Append validation metrics to the respective lists\n",
        "        val_losses.append(val_loss_combined)\n",
        "        val_accuracies.append(val_acc_combined)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        print(f'Validation Combined Loss: {val_loss_combined:.4f} '\n",
        "                f'Acc: {val_acc_combined:.4f}')\n",
        "        print(f'Validation Precision: {precision:.4f}, '\n",
        "                f'Recall: {recall:.4f}, F1-score: {f1:.4f}')\n",
        "\n",
        "        # Early stopping: check if the validation loss has improved\n",
        "        if val_loss_combined < best_val_loss:\n",
        "            best_val_loss = val_loss_combined  # Update the best validation loss\n",
        "            epochs_no_improve = 0  # Reset the counter\n",
        "\n",
        "            # Save the model state if a new best validation loss is found\n",
        "            print(f\"New best model found! Saving model with validation \"\n",
        "                    f\"loss: {best_val_loss:.4f}\")\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            epochs_no_improve += 1  # Increment the counter for epochs without improvement\n",
        "            if epochs_no_improve >= early_stopping_patience:  # Check if patience limit is reached\n",
        "                print(f'Early stopping at epoch {epoch + 1} due to {epochs_no_improve} epochs without improvement')  # Print a message indicating early stopping\n",
        "                break  # Exit the training loop\n",
        "\n",
        "        # Step the learning rate scheduler to adjust the learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "    # Plotting results: save the metrics to a file for analysis\n",
        "    plot_training_results(train_losses, val_losses, train_accuracies, val_accuracies, precisions, recalls, f1_scores, filename)\n",
        "\n",
        "    return best_val_loss  # Return the best validation loss achieved during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ufOyW7RNhV6I"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "**test**\n",
        "\n",
        "This function evaluates the model's performance on the test set by calculating the test accuracy\n",
        "and additional metrics such as precision, recall, and F1 score. It also identifies and logs misclassified\n",
        "examples, allowing for further analysis of the model's performance.\n",
        "\n",
        "Args:\n",
        "    model (nn.Module): The neural network model to test.\n",
        "    testloader (DataLoader): The DataLoader for the test dataset.\n",
        "\n",
        "Returns:\n",
        "    tuple: A tuple containing:\n",
        "        - float: The computed test accuracy.\n",
        "        - float: The computed precision.\n",
        "        - float: The computed recall.\n",
        "        - float: The computed F1 score.\n",
        "        - ndarray: The confusion matrix.\n",
        "\"\"\"\n",
        "def test(model, testloader):\n",
        "     # Set the model to evaluation mode, disabling dropout and batch normalization\n",
        "    model.eval()\n",
        "\n",
        "    test_running_corrects_combined = 0  # Initialize the count of correct predictions\n",
        "\n",
        "    all_labels = []  # List to store all true labels for metrics computation\n",
        "    all_preds_combined = []  # List to store all predictions for metrics computation\n",
        "\n",
        "    # Disable gradient calculation for testing (saves memory and computation)\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            # Move data to the appropriate device\n",
        "            images = batch['image'].to(device)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # Forward pass: compute model outputs for the current batch\n",
        "            combined_outputs = model(\n",
        "                images, input_ids, attention_mask\n",
        "            )\n",
        "\n",
        "            # Get predictions by finding the class with the maximum score\n",
        "            _, preds_combined = torch.max(combined_outputs, 1)\n",
        "\n",
        "            # Update the count of correct predictions\n",
        "            test_running_corrects_combined += torch.sum(\n",
        "                preds_combined == labels.data\n",
        "            )\n",
        "\n",
        "            # Collect all labels and predictions for metric computations\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds_combined.extend(preds_combined.cpu().numpy())\n",
        "\n",
        "    # Compute test accuracy\n",
        "    test_acc_combined = test_running_corrects_combined.double() / len(testloader.dataset)\n",
        "\n",
        "    # Compute additional metrics like precision, recall, and F1 score\n",
        "    precision, recall, f1 = compute_metrics(all_labels, all_preds_combined)\n",
        "\n",
        "    # Compute confusion matrix for detailed error analysis\n",
        "    conf_mat = confusion_matrix(all_labels, all_preds_combined)\n",
        "\n",
        "    # Return test accuracy and computed metrics\n",
        "    return test_acc_combined, precision, recall, f1, conf_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs_vWFoU3hS8"
      },
      "source": [
        "# Main Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvBtpHsRiCHe"
      },
      "source": [
        "## Pre-process data, define criterion, and initialize the multimodal model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv0wqTlQhYqY"
      },
      "outputs": [],
      "source": [
        "# Preprocess data and create data loaders\n",
        "trainloader, valloader, testloader, class_weights_tensor = data_preprocessing()\n",
        "\n",
        "# Define the loss function with class weights\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "# Initialize the model\n",
        "model = GarbageClassifier(num_classes=len(class_names), dropout_rate=DROPOUT_RATE).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOqAMP7N2xPB"
      },
      "source": [
        "## Define filenames for metrics plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5IuOrrU2vPl"
      },
      "outputs": [],
      "source": [
        "  filename_confusion_matrix = \"/home/shaakira.gadiwan/assignment2/conf_mat.png\"\n",
        "  filename_metrics_plot = \"/home/shaakira.gadiwan/assignment2/metrics_plot.png\"\n",
        "  filename_metrics_plot_fine_tuning = \"/home/shaakira.gadiwan/assignment2/metrics_plot_fine_tuning.png\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1rUkMbB237k"
      },
      "source": [
        "## Create the trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8K1CwAR27SF"
      },
      "outputs": [],
      "source": [
        "# Freeze layers of the image model and unfreeze specific layers for training\n",
        "for param in model.image_model.model.parameters():\n",
        "    param.requires_grad = False  # Freeze all layers initially\n",
        "for param in model.image_model.model.layer4.parameters():\n",
        "    param.requires_grad = True  # Unfreeze layer4 for training\n",
        "for param in model.image_model.feature_extractor.parameters():\n",
        "    param.requires_grad = True  # Unfreeze feature extractor for training\n",
        "\n",
        "# Unfreeze layers of the text model for training\n",
        "for param in model.text_model.bert.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in model.text_model.feature_extractor.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Collect trainable parameters with specific learning rates\n",
        "trainable_params = [\n",
        "    {'params': model.image_model.model.layer4.parameters(), 'lr': LEARNING_RATE * 0.1},\n",
        "    {'params': model.image_model.feature_extractor.parameters(), 'lr': LEARNING_RATE},\n",
        "    {'params': model.text_model.bert.parameters(), 'lr': LEARNING_RATE * 0.1},\n",
        "    {'params': model.text_model.feature_extractor.parameters(), 'lr': LEARNING_RATE},\n",
        "    {'params': model.fusion.parameters(), 'lr': LEARNING_RATE},\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwnf-JK53CSi"
      },
      "source": [
        "## Iterate through the first phase of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAU9dkuz3Kdb"
      },
      "outputs": [],
      "source": [
        "# Initialize best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# First phase of training\n",
        "best_val_loss = train_validate_model(model, trainloader, valloader, criterion, trainable_params, best_val_loss, 20, filename_metrics_plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiFYV2wP3S9Z"
      },
      "source": [
        "## Load best model for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YVFSvCc3V-P"
      },
      "outputs": [],
      "source": [
        "# Load the best model after first phase of training\n",
        "model.load_state_dict(torch.load('best_model.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox0N4se53bWW"
      },
      "source": [
        "## Create the trainable parameters for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRMU9mfh3tUq"
      },
      "outputs": [],
      "source": [
        "# Freeze and unfreeze layers for further training\n",
        "for param in model.image_model.model.parameters():\n",
        "    param.requires_grad = False  # Freeze all layers again\n",
        "for param in model.image_model.model.layer2.parameters():\n",
        "    param.requires_grad = True  # Unfreeze layer2 for training\n",
        "for param in model.image_model.model.layer3.parameters():\n",
        "    param.requires_grad = True  # Unfreeze layer3 for training\n",
        "for param in model.image_model.model.layer4.parameters():\n",
        "    param.requires_grad = True  # Keep layer4 unfrozen\n",
        "for param in model.image_model.feature_extractor.parameters():\n",
        "    param.requires_grad = True  # Keep feature extractor unfrozen\n",
        "\n",
        "# Unfreeze layers of the text model again for training\n",
        "for param in model.text_model.bert.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in model.text_model.feature_extractor.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Collect trainable parameters for the second phase with adjusted learning rates\n",
        "trainable_params = [\n",
        "    {'params': model.image_model.model.layer2.parameters(), 'lr': LEARNING_RATE * 0.01},\n",
        "    {'params': model.image_model.model.layer3.parameters(), 'lr': LEARNING_RATE * 0.01},\n",
        "    {'params': model.image_model.model.layer4.parameters(), 'lr': LEARNING_RATE * 0.01},\n",
        "    {'params': model.image_model.feature_extractor.parameters(), 'lr': LEARNING_RATE * 0.1},\n",
        "    {'params': model.text_model.bert.parameters(), 'lr': LEARNING_RATE * 0.01},\n",
        "    {'params': model.text_model.feature_extractor.parameters(), 'lr': LEARNING_RATE * 0.1},\n",
        "    {'params': model.fusion.parameters(), 'lr': LEARNING_RATE},\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMebbwmh3w7V"
      },
      "source": [
        "## Iterate through the second phase of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqJsBDXq324S"
      },
      "outputs": [],
      "source": [
        "# Second phase of training\n",
        "train_validate_model(model, trainloader, valloader, criterion, trainable_params, best_val_loss, 5, filename_metrics_plot_fine_tuning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfsaLZmO362V"
      },
      "source": [
        "## Load best model for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5xGnYKD3-bQ"
      },
      "outputs": [],
      "source": [
        "# Load the best model after the second phase of training\n",
        "model.load_state_dict(torch.load('best_model.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CePs4BVu4Bg2"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNw_I5A74Dn5"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_acc_combined, precision, recall, f1, conf_mat = test(model, testloader)\n",
        "\n",
        "# Print test results\n",
        "print(f'Test Combined Accuracy: {test_acc_combined:.4f}')\n",
        "print(f'Test Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHAb4TAi4VCN"
      },
      "source": [
        "## Create the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP7kHdLV4Xb8"
      },
      "outputs": [],
      "source": [
        "# Plot confusion matrix\n",
        "plot_confusion_matrix(conf_mat, filename_confusion_matrix)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
